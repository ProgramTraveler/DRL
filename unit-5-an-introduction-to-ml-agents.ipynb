{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chhelp/unit-5-an-introduction-to-ml-agents?scriptVersionId=143836193\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# clone 仓库并安装依赖","metadata":{}},{"cell_type":"code","source":"%%capture\n# Clone the repository\n!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:27:47.410422Z","iopub.execute_input":"2023-09-22T06:27:47.411279Z","iopub.status.idle":"2023-09-22T06:27:48.491535Z","shell.execute_reply.started":"2023-09-22T06:27:47.41123Z","shell.execute_reply":"2023-09-22T06:27:48.489884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n# Go inside the repository and install the package\n%cd ml-agents\n!pip3 install -e ./ml-agents-envs\n!pip3 install -e ./ml-agents","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:25:41.156056Z","iopub.execute_input":"2023-09-22T06:25:41.156576Z","iopub.status.idle":"2023-09-22T06:27:34.734474Z","shell.execute_reply.started":"2023-09-22T06:25:41.15653Z","shell.execute_reply":"2023-09-22T06:27:34.733033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here, we create training-envs-executables and linux\n!mkdir ./training-envs-executables\n!mkdir ./training-envs-executables/linux","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:27:36.774528Z","iopub.execute_input":"2023-09-22T06:27:36.774948Z","iopub.status.idle":"2023-09-22T06:27:38.801714Z","shell.execute_reply.started":"2023-09-22T06:27:36.774914Z","shell.execute_reply":"2023-09-22T06:27:38.800309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5\" -O ./training-envs-executables/linux/SnowballTarget.zip && rm -rf /tmp/cookies.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:27:38.805307Z","iopub.execute_input":"2023-09-22T06:27:38.80631Z","iopub.status.idle":"2023-09-22T06:27:41.10088Z","shell.execute_reply.started":"2023-09-22T06:27:38.806271Z","shell.execute_reply":"2023-09-22T06:27:41.099837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:27:41.103091Z","iopub.execute_input":"2023-09-22T06:27:41.10346Z","iopub.status.idle":"2023-09-22T06:27:43.225088Z","shell.execute_reply.started":"2023-09-22T06:27:41.103428Z","shell.execute_reply":"2023-09-22T06:27:43.223643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!chmod -R 755 ./training-envs-executables/linux/SnowballTarget","metadata":{"execution":{"iopub.status.busy":"2023-09-22T06:27:43.227437Z","iopub.execute_input":"2023-09-22T06:27:43.227938Z","iopub.status.idle":"2023-09-22T06:27:44.263204Z","shell.execute_reply.started":"2023-09-22T06:27:43.227893Z","shell.execute_reply":"2023-09-22T06:27:44.26199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the SnowballTarget config file\n- In ML-Agents, you define the **training hyperparameters into config.yaml files.**\n\nThere are multiple hyperparameters. To know them better, you should check for each explanation with [the documentation](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)\n\n\nSo you need to create a `SnowballTarget.yaml` config file in ./content/ml-agents/config/ppo/\n\nWe'll give you here a first version of this config (to copy and paste into your `SnowballTarget.yaml file`), **but you should modify it**.\n\n```\nbehaviors:\n  SnowballTarget:\n    trainer_type: ppo\n    summary_freq: 10000\n    keep_checkpoints: 10\n    checkpoint_interval: 50000\n    max_steps: 200000\n    time_horizon: 64\n    threaded: true\n    hyperparameters:\n      learning_rate: 0.0003\n      learning_rate_schedule: linear\n      batch_size: 128\n      buffer_size: 2048\n      beta: 0.005\n      epsilon: 0.2\n      lambd: 0.95\n      num_epoch: 3\n    network_settings:\n      normalize: false\n      hidden_units: 256\n      num_layers: 2\n      vis_encode_type: simple\n    reward_signals:\n      extrinsic:\n        gamma: 0.99\n        strength: 1.0\n```","metadata":{}},{"cell_type":"markdown","source":"# Train the agent","metadata":{}},{"cell_type":"code","source":"!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics","metadata":{},"execution_count":null,"outputs":[]}]}