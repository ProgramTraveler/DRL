{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chhelp/unit1-land-on-the-moon?scriptVersionId=143492782\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Hugging Face 的在月球上降落\n\n* 安装依赖 将安装多个依赖\n    * gymnasium[box2d] 包含 LunarLander-v2 环境\n    * stable-baselines3[extra] 深度强化学习库\n    * huggingface_sb3 Stable-baseline3 的附加代码 用于从 Hugging Face Hub 加载和上传模型","metadata":{}},{"cell_type":"code","source":"!apt install swig cmake","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:39:15.798448Z","iopub.execute_input":"2023-09-19T06:39:15.799235Z","iopub.status.idle":"2023-09-19T06:39:22.580409Z","shell.execute_reply.started":"2023-09-19T06:39:15.799197Z","shell.execute_reply":"2023-09-19T06:39:22.579348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:39:22.583001Z","iopub.execute_input":"2023-09-19T06:39:22.583721Z","iopub.status.idle":"2023-09-19T06:40:24.27987Z","shell.execute_reply.started":"2023-09-19T06:39:22.583684Z","shell.execute_reply":"2023-09-19T06:40:24.278724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 使用 Colab 生成重播视频 需要一个虚拟屏幕来渲染环境 从而记录帧\n* 以下单元格将安装虚拟屏幕库并创建运行虚拟屏幕","metadata":{}},{"cell_type":"code","source":"!sudo apt-get update\n!sudo apt-get install -y python3-opengl\n!apt install ffmpeg\n!apt install xvfb\n!pip3 install pyvirtualdisplay","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:40:24.282505Z","iopub.execute_input":"2023-09-19T06:40:24.283655Z","iopub.status.idle":"2023-09-19T06:40:54.377579Z","shell.execute_reply.started":"2023-09-19T06:40:24.283618Z","shell.execute_reply":"2023-09-19T06:40:54.376235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 虚拟屏幕\nfrom pyvirtualdisplay import Display\n\nvirtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:40:54.379679Z","iopub.execute_input":"2023-09-19T06:40:54.380076Z","iopub.status.idle":"2023-09-19T06:40:55.002323Z","shell.execute_reply.started":"2023-09-19T06:40:54.380042Z","shell.execute_reply":"2023-09-19T06:40:55.001368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 导入 Huggingface_hub 包 以便能够上传和下载经过训练的模型","metadata":{}},{"cell_type":"code","source":"import gymnasium\n\nfrom huggingface_sb3 import load_from_hub, package_to_hub\nfrom huggingface_hub import notebook_login # 登录 Hugging Face 帐户以便能够将模型上传到 Hub\n\nfrom stable_baselines3 import PPO # 直接使用的 PPO 算法\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.monitor import Monitor","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-09-19T07:12:59.758538Z","iopub.status.idle":"2023-09-19T07:12:59.759022Z","shell.execute_reply.started":"2023-09-19T07:12:59.758774Z","shell.execute_reply":"2023-09-19T07:12:59.758797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Gymnasium\n    * 使用 gymnasium.make() 来创建环境\n    * 使用 observation() = env.reset() 将环境重置为初始状态\n* 在每一个 step\n    * 使用我们的模型获取一个 action 在例子中 我们采用随机操作\n    * 使用 env.step(action) 在环境中执行这个 action 并得到\n        * observation: 新状态($S_(t + 1)$)\n        * reward: 执行 action 后获得的奖励\n        * terminated: episode 是否结束(agent 到达终止状态)\n        * truncated: 在新版本中引入 它指示时间限制或者 agent 是否超出环境范围\n        * info: 提供附加信息(取决于环境) 是一个字典\n* 如果 episoide 终止\n    * 使用 observation = env.reset() 将环境重置为初始环境","metadata":{}},{"cell_type":"code","source":"# 这只是针对上面步骤的一个列子\nimport gymnasium as gym\n\n# 创建一个名为 LunarLander-v2 的一个环境\nenv = gym.make(\"LunarLander-v2\")\n\n# 重置环境\nobservation, info = env.reset()\n\nfor _ in range(20):\n    # 采取一个随机动作\n    action = env.action_space.sample()\n    print(\"Action taken: \", action)\n    \n    # 在环境中采取这个动作 并获取 next_state reward terminated truncated info\n    observation, reward, terminated, truncated, info = env.step(action)\n    \n    # 如果游戏结束(这里指的是降落或者坠毁) 或者时间耗尽\n    if terminated or truncated:\n        # 重置环境\n        print(\"Enviroment is reset\")\n        observation, info = env.reset()\n\n# 清理环境\nenv.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:41:08.40452Z","iopub.execute_input":"2023-09-19T06:41:08.405159Z","iopub.status.idle":"2023-09-19T06:41:08.473504Z","shell.execute_reply.started":"2023-09-19T06:41:08.405125Z","shell.execute_reply":"2023-09-19T06:41:08.472391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练 agent(月球着陆器) 正确登录月球","metadata":{}},{"cell_type":"code","source":"# 创建环境\nenv = gym.make(\"LunarLander-v2\")\nenv.reset()\n\nprint(\"_____OBSERVATION SPACE_____ \\n\")\nprint(\"Observation Space Shape\", env.observation_space.shape)\nprint(\"Sample observation\", env.observation_space.sample()) # 获取随机的状态","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:41:08.475497Z","iopub.execute_input":"2023-09-19T06:41:08.4763Z","iopub.status.idle":"2023-09-19T06:41:08.486602Z","shell.execute_reply.started":"2023-09-19T06:41:08.476263Z","shell.execute_reply":"2023-09-19T06:41:08.485375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Observation Space Shape 是一个大小为 8 的向量 每个值都包含不同信息\n    - Horizontal pad coordinate (x)\n    - Vertical pad coordinate (y)\n    - Horizontal speed (x)\n    - Vertical speed (y)\n    - Angle\n    - Angular speed\n    - If the left leg contact point has touched the land (boolean)\n    - If the right leg contact point has touched the land (boolean)","metadata":{}},{"cell_type":"code","source":"print(\"\\n _____ACTION SPACE_____ \\n\")\nprint(\"Action Space Shape\", env.action_space.n)\nprint(\"Action Space Sample\", env.action_space.sample()) # 获取随机动作","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:41:08.488574Z","iopub.execute_input":"2023-09-19T06:41:08.488975Z","iopub.status.idle":"2023-09-19T06:41:08.496871Z","shell.execute_reply.started":"2023-09-19T06:41:08.488939Z","shell.execute_reply":"2023-09-19T06:41:08.495665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 动作空间(agent 可能采取的一组动作)是离散的 有四个可用的动作\n    - Action 0: Do nothing,\n    - Action 1: Fire left orientation engine,\n    - Action 2: Fire the main engine,\n    - Action 3: Fire right orientation engine.\n* 对每一个 step 的奖励设置\n    - Is increased/decreased the closer/further the lander is to the landing pad.\n    -  Is increased/decreased the slower/faster the lander is moving.\n    - Is decreased the more the lander is tilted (angle not horizontal).\n    - Is increased by 10 points for each leg that is in contact with the ground.\n    - Is decreased by 0.03 points each frame a side engine is firing.\n    - Is decreased by 0.3 points each frame the main engine is firing.\n* 对每个 episode 着陆器因坠毁或者安全着陆分别获得 -100 和 +100 的额外奖励\n* 如果一个 episode 的得分至少为 200 分则视为一个解决方案","metadata":{}},{"cell_type":"code","source":"# 矢量化环境\n# 创建一个由 16 个环境组成的矢量化环境(一种将多个独立环境堆叠到单个环境中的方法)\n# 这样在训练中就会有更多样化的体验\n# 创建环境\nenv = make_vec_env('LunarLander-v2', n_envs=16)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:41:08.498699Z","iopub.execute_input":"2023-09-19T06:41:08.499249Z","iopub.status.idle":"2023-09-19T06:41:08.523374Z","shell.execute_reply.started":"2023-09-19T06:41:08.499079Z","shell.execute_reply":"2023-09-19T06:41:08.522232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 使用第一个深度强化学习库 Stable Baselines3(SB3)\n* SB3 是通过 PyTorch 实现的强化学习组\n* 在当前代码中 使用的是 SB3 中的 PPO 算法","metadata":{}},{"cell_type":"code","source":"# 创建环境\nenv = gym.make(\"LunarLander-v2\")\n\n'''\n# 定义使用的 agent 并实例化该模型\nmodel = PPO('MlpPolicy', env, verbose=1)\n# 训练模型 并定义训练的 timesteps\nmodel.learn(total_timesteps=int(2e5))\n'''\n\n# 添加一些参数 来加速训练的过程\nmodel = PPO(\n    policy = 'MlpPolicy',\n    env = env,\n    n_steps = 1024,\n    batch_size = 64,\n    n_epochs = 4,\n    gamma = 0.999,\n    gae_lambda = 0.98,\n    ent_coef = 0.01,\n    verbose=1)\n\n# 训练 agent 1,000,000 timesteps\nmodel.learn(total_timesteps=1000000)\n# 保存模型\nmodel_name = \"ppo-LunarLander-v2\"\nmodel.save(model_name)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-09-19T06:41:08.52504Z","iopub.execute_input":"2023-09-19T06:41:08.525501Z","iopub.status.idle":"2023-09-19T07:12:54.507964Z","shell.execute_reply.started":"2023-09-19T06:41:08.525465Z","shell.execute_reply":"2023-09-19T07:12:54.506966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 评估训练的代理\n* 在 Stable-Baselines3 提供了一种方法 evaluate_policy","metadata":{}},{"cell_type":"code","source":"eval_env = Monitor(gym.make(\"LunarLander-v2\"))\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:12:54.509261Z","iopub.execute_input":"2023-09-19T07:12:54.509637Z","iopub.status.idle":"2023-09-19T07:12:58.151402Z","shell.execute_reply.started":"2023-09-19T07:12:54.509605Z","shell.execute_reply":"2023-09-19T07:12:58.150202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 上传到 hugging hub 请修改username 和 repo_name","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:12:58.153072Z","iopub.execute_input":"2023-09-19T07:12:58.154226Z","iopub.status.idle":"2023-09-19T07:12:58.190076Z","shell.execute_reply.started":"2023-09-19T07:12:58.154184Z","shell.execute_reply":"2023-09-19T07:12:58.189109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:17:42.001003Z","iopub.execute_input":"2023-09-19T07:17:42.001468Z","iopub.status.idle":"2023-09-19T07:18:06.918545Z","shell.execute_reply.started":"2023-09-19T07:17:42.001434Z","shell.execute_reply":"2023-09-19T07:18:06.91734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom stable_baselines3.common.env_util import make_vec_env\n\nfrom huggingface_sb3 import package_to_hub\n\n# PLACE the variables you've just defined two cells above\n# Define the name of the environment\nenv_id = \"LunarLander-v2\"\n\n# TODO: Define the model architecture we used\nmodel_architecture = \"PPO\"\n\n## Define a repo_id\n## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n## CHANGE WITH YOUR REPO ID\nrepo_id = \"Solitary12138/Load_Moon\"  # Change with your repo id, you can't push with mine 😄\n\n## Define the commit message\ncommit_message = \"Upload PPO LunarLander-v2 trained agent\"\n\n# Create the evaluation env and set the render_mode=\"rgb_array\"\neval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode=\"rgb_array\"))])\n\n# PLACE the package_to_hub function you've just filled here\npackage_to_hub(\n    model=model,  # Our trained model\n    model_name=model_name,  # The name of our trained model\n    model_architecture=model_architecture,  # The model architecture we used: in our case PPO\n    env_id=env_id,  # Name of the environment\n    eval_env=eval_env,  # Evaluation Environment\n    repo_id=repo_id,  # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n    commit_message=commit_message,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:18:18.788256Z","iopub.execute_input":"2023-09-19T07:18:18.788895Z","iopub.status.idle":"2023-09-19T07:18:31.376429Z","shell.execute_reply.started":"2023-09-19T07:18:18.788861Z","shell.execute_reply":"2023-09-19T07:18:31.375427Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
