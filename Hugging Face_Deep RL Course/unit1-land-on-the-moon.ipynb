{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hugging Face çš„åœ¨æœˆçƒä¸Šé™è½\n\n* å®‰è£…ä¾èµ– å°†å®‰è£…å¤šä¸ªä¾èµ–\n    * gymnasium[box2d] åŒ…å« LunarLander-v2 ç¯å¢ƒ\n    * stable-baselines3[extra] æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“\n    * huggingface_sb3 Stable-baseline3 çš„é™„åŠ ä»£ç  ç”¨äºä» Hugging Face Hub åŠ è½½å’Œä¸Šä¼ æ¨¡å‹","metadata":{}},{"cell_type":"code","source":"!apt install swig cmake","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:52:57.411164Z","iopub.execute_input":"2023-09-18T10:52:57.411817Z","iopub.status.idle":"2023-09-18T10:53:05.280825Z","shell.execute_reply.started":"2023-09-18T10:52:57.411750Z","shell.execute_reply":"2023-09-18T10:53:05.279552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:53:05.283843Z","iopub.execute_input":"2023-09-18T10:53:05.284222Z","iopub.status.idle":"2023-09-18T10:54:10.272780Z","shell.execute_reply.started":"2023-09-18T10:53:05.284182Z","shell.execute_reply":"2023-09-18T10:54:10.271517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ä½¿ç”¨ Colab ç”Ÿæˆé‡æ’­è§†é¢‘ éœ€è¦ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥æ¸²æŸ“ç¯å¢ƒ ä»è€Œè®°å½•å¸§\n* ä»¥ä¸‹å•å…ƒæ ¼å°†å®‰è£…è™šæ‹Ÿå±å¹•åº“å¹¶åˆ›å»ºè¿è¡Œè™šæ‹Ÿå±å¹•","metadata":{}},{"cell_type":"code","source":"!sudo apt-get update\n!sudo apt-get install -y python3-openg1\n!apt install ffmpeg\n!apt install xvfb\n!pip3 install pyvirtualdisplay","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:54:10.275887Z","iopub.execute_input":"2023-09-18T10:54:10.276484Z","iopub.status.idle":"2023-09-18T10:54:34.558326Z","shell.execute_reply.started":"2023-09-18T10:54:10.276443Z","shell.execute_reply":"2023-09-18T10:54:34.556909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# è™šæ‹Ÿå±å¹•\nfrom pyvirtualdisplay import Display\n\nvirtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:54:34.562037Z","iopub.execute_input":"2023-09-18T10:54:34.562522Z","iopub.status.idle":"2023-09-18T10:54:35.756859Z","shell.execute_reply.started":"2023-09-18T10:54:34.562482Z","shell.execute_reply":"2023-09-18T10:54:35.755836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* å¯¼å…¥ Huggingface_hub åŒ… ä»¥ä¾¿èƒ½å¤Ÿä¸Šä¼ å’Œä¸‹è½½ç»è¿‡è®­ç»ƒçš„æ¨¡å‹","metadata":{}},{"cell_type":"code","source":"import gymnasium\n\nfrom huggingface_sb3 import load_from_hub, package_to_hub\nfrom huggingface_hub import notebook_login # ç™»å½• Hugging Face å¸æˆ·ä»¥ä¾¿èƒ½å¤Ÿå°†æ¨¡å‹ä¸Šä¼ åˆ° Hub\n\nfrom stable_baselines3 import PPO # ç›´æ¥ä½¿ç”¨çš„ PPO ç®—æ³•\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.monitor import Monitor","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:55:46.452887Z","iopub.execute_input":"2023-09-18T10:55:46.453267Z","iopub.status.idle":"2023-09-18T10:55:46.460352Z","shell.execute_reply.started":"2023-09-18T10:55:46.453237Z","shell.execute_reply":"2023-09-18T10:55:46.458309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Gymnasium\n    * ä½¿ç”¨ gymnasium.make() æ¥åˆ›å»ºç¯å¢ƒ\n    * ä½¿ç”¨ observation() = env.reset() å°†ç¯å¢ƒé‡ç½®ä¸ºåˆå§‹çŠ¶æ€\n* åœ¨æ¯ä¸€ä¸ª step\n    * ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è·å–ä¸€ä¸ª action åœ¨ä¾‹å­ä¸­ æˆ‘ä»¬é‡‡ç”¨éšæœºæ“ä½œ\n    * ä½¿ç”¨ env.step(action) åœ¨ç¯å¢ƒä¸­æ‰§è¡Œè¿™ä¸ª action å¹¶å¾—åˆ°\n        * observation: æ–°çŠ¶æ€($S_(t + 1)$)\n        * reward: æ‰§è¡Œ action åè·å¾—çš„å¥–åŠ±\n        * terminated: episode æ˜¯å¦ç»“æŸ(agent åˆ°è¾¾ç»ˆæ­¢çŠ¶æ€)\n        * truncated: åœ¨æ–°ç‰ˆæœ¬ä¸­å¼•å…¥ å®ƒæŒ‡ç¤ºæ—¶é—´é™åˆ¶æˆ–è€… agent æ˜¯å¦è¶…å‡ºç¯å¢ƒèŒƒå›´\n        * info: æä¾›é™„åŠ ä¿¡æ¯(å–å†³äºç¯å¢ƒ) æ˜¯ä¸€ä¸ªå­—å…¸\n* å¦‚æœ episoide ç»ˆæ­¢\n    * ä½¿ç”¨ observation = env.reset() å°†ç¯å¢ƒé‡ç½®ä¸ºåˆå§‹ç¯å¢ƒ","metadata":{}},{"cell_type":"code","source":"# è¿™åªæ˜¯é’ˆå¯¹ä¸Šé¢æ­¥éª¤çš„ä¸€ä¸ªåˆ—å­\nimport gymnasium as gym\n\n# åˆ›å»ºä¸€ä¸ªåä¸º LunarLander-v2 çš„ä¸€ä¸ªç¯å¢ƒ\nenv = gym.make(\"LunarLander-v2\")\n\n# é‡ç½®ç¯å¢ƒ\nobservation, info = env.reset()\n\nfor _ in range(20):\n    # é‡‡å–ä¸€ä¸ªéšæœºåŠ¨ä½œ\n    action = env.action_space.sample()\n    print(\"Action taken: \", action)\n    \n    # åœ¨ç¯å¢ƒä¸­é‡‡å–è¿™ä¸ªåŠ¨ä½œ å¹¶è·å– next_state reward terminated truncated info\n    observation, reward, terminated, truncated, info = env.step(action)\n    \n    # å¦‚æœæ¸¸æˆç»“æŸ(è¿™é‡ŒæŒ‡çš„æ˜¯é™è½æˆ–è€…å æ¯) æˆ–è€…æ—¶é—´è€—å°½\n    if terminated or truncated:\n        # é‡ç½®ç¯å¢ƒ\n        print(\"Enviroment is reset\")\n        observation, info = env.reset()\n\n# æ¸…ç†ç¯å¢ƒ\nenv.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:54:57.143804Z","iopub.execute_input":"2023-09-18T10:54:57.144950Z","iopub.status.idle":"2023-09-18T10:54:57.224202Z","shell.execute_reply.started":"2023-09-18T10:54:57.144911Z","shell.execute_reply":"2023-09-18T10:54:57.222951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# è®­ç»ƒ agent(æœˆçƒç€é™†å™¨) æ­£ç¡®ç™»å½•æœˆçƒ","metadata":{}},{"cell_type":"code","source":"# åˆ›å»ºç¯å¢ƒ\nenv = gym.make(\"LunarLander-v2\")\nenv.reset()\n\nprint(\"_____OBSERVATION SPACE_____ \\n\")\nprint(\"Observation Space Shape\", env.observation_space.shape)\nprint(\"Sample observation\", env.observation_space.sample()) # è·å–éšæœºçš„çŠ¶æ€","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:55:52.834499Z","iopub.execute_input":"2023-09-18T10:55:52.834897Z","iopub.status.idle":"2023-09-18T10:55:52.845196Z","shell.execute_reply.started":"2023-09-18T10:55:52.834863Z","shell.execute_reply":"2023-09-18T10:55:52.843881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Observation Space Shape æ˜¯ä¸€ä¸ªå¤§å°ä¸º 8 çš„å‘é‡ æ¯ä¸ªå€¼éƒ½åŒ…å«ä¸åŒä¿¡æ¯\n    - Horizontal pad coordinate (x)\n    - Vertical pad coordinate (y)\n    - Horizontal speed (x)\n    - Vertical speed (y)\n    - Angle\n    - Angular speed\n    - If the left leg contact point has touched the land (boolean)\n    - If the right leg contact point has touched the land (boolean)","metadata":{}},{"cell_type":"code","source":"print(\"\\n _____ACTION SPACE_____ \\n\")\nprint(\"Action Space Shape\", env.action_space.n)\nprint(\"Action Space Sample\", env.action_space.sample()) # è·å–éšæœºåŠ¨ä½œ","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:55:54.992641Z","iopub.execute_input":"2023-09-18T10:55:54.993973Z","iopub.status.idle":"2023-09-18T10:55:55.000814Z","shell.execute_reply.started":"2023-09-18T10:55:54.993928Z","shell.execute_reply":"2023-09-18T10:55:54.999520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* åŠ¨ä½œç©ºé—´(agent å¯èƒ½é‡‡å–çš„ä¸€ç»„åŠ¨ä½œ)æ˜¯ç¦»æ•£çš„ æœ‰å››ä¸ªå¯ç”¨çš„åŠ¨ä½œ\n    - Action 0: Do nothing,\n    - Action 1: Fire left orientation engine,\n    - Action 2: Fire the main engine,\n    - Action 3: Fire right orientation engine.\n* å¯¹æ¯ä¸€ä¸ª step çš„å¥–åŠ±è®¾ç½®\n    - Is increased/decreased the closer/further the lander is to the landing pad.\n    -  Is increased/decreased the slower/faster the lander is moving.\n    - Is decreased the more the lander is tilted (angle not horizontal).\n    - Is increased by 10 points for each leg that is in contact with the ground.\n    - Is decreased by 0.03 points each frame a side engine is firing.\n    - Is decreased by 0.3 points each frame the main engine is firing.\n* å¯¹æ¯ä¸ª episode ç€é™†å™¨å› å æ¯æˆ–è€…å®‰å…¨ç€é™†åˆ†åˆ«è·å¾— -100 å’Œ +100 çš„é¢å¤–å¥–åŠ±\n* å¦‚æœä¸€ä¸ª episode çš„å¾—åˆ†è‡³å°‘ä¸º 200 åˆ†åˆ™è§†ä¸ºä¸€ä¸ªè§£å†³æ–¹æ¡ˆ","metadata":{}},{"cell_type":"code","source":"# çŸ¢é‡åŒ–ç¯å¢ƒ\n# åˆ›å»ºä¸€ä¸ªç”± 16 ä¸ªç¯å¢ƒç»„æˆçš„çŸ¢é‡åŒ–ç¯å¢ƒ(ä¸€ç§å°†å¤šä¸ªç‹¬ç«‹ç¯å¢ƒå †å åˆ°å•ä¸ªç¯å¢ƒä¸­çš„æ–¹æ³•)\n# è¿™æ ·åœ¨è®­ç»ƒä¸­å°±ä¼šæœ‰æ›´å¤šæ ·åŒ–çš„ä½“éªŒ\n# åˆ›å»ºç¯å¢ƒ\nenv = make_vec_env('LunarLander-v2', n_envs=16)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:56:19.376475Z","iopub.execute_input":"2023-09-18T10:56:19.376861Z","iopub.status.idle":"2023-09-18T10:56:19.397579Z","shell.execute_reply.started":"2023-09-18T10:56:19.376828Z","shell.execute_reply":"2023-09-18T10:56:19.396501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ä½¿ç”¨ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ Stable Baselines3(SB3)\n* SB3 æ˜¯é€šè¿‡ PyTorch å®ç°çš„å¼ºåŒ–å­¦ä¹ ç»„\n* åœ¨å½“å‰ä»£ç ä¸­ ä½¿ç”¨çš„æ˜¯ SB3 ä¸­çš„ PPO ç®—æ³•","metadata":{}},{"cell_type":"code","source":"# åˆ›å»ºç¯å¢ƒ\nenv = gym.make(\"LunarLander-v2\")\n\n'''\n# å®šä¹‰ä½¿ç”¨çš„ agent å¹¶å®ä¾‹åŒ–è¯¥æ¨¡å‹\nmodel = PPO('MlpPolicy', env, verbose=1)\n# è®­ç»ƒæ¨¡å‹ å¹¶å®šä¹‰è®­ç»ƒçš„ timesteps\nmodel.learn(total_timesteps=int(2e5))\n'''\n\n# æ·»åŠ ä¸€äº›å‚æ•° æ¥åŠ é€Ÿè®­ç»ƒçš„è¿‡ç¨‹\nmodel = PPO(\n    policy = 'MlpPolicy',\n    env = env,\n    n_steps = 1024,\n    batch_size = 64,\n    n_epochs = 4,\n    gamma = 0.999,\n    gae_lambda = 0.98,\n    ent_coef = 0.01,\n    verbose=1)\n\n# è®­ç»ƒ agent 1,000,000 timesteps\nmodel.learn(total_timesteps=1000000)\n# ä¿å­˜æ¨¡å‹\nmodel_name = \"ppo-LunarLander-v2\"\nmodel.save(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:56:23.439832Z","iopub.execute_input":"2023-09-18T10:56:23.441014Z","iopub.status.idle":"2023-09-18T11:28:48.537555Z","shell.execute_reply.started":"2023-09-18T10:56:23.440973Z","shell.execute_reply":"2023-09-18T11:28:48.536366Z"},"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* è¯„ä¼°è®­ç»ƒçš„ä»£ç†\n* åœ¨ Stable-Baselines3 æä¾›äº†ä¸€ç§æ–¹æ³• evaluate_policy","metadata":{}},{"cell_type":"code","source":"eval_env = Monitor(gym.make(\"LunarLander-v2\"))\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T11:32:15.085698Z","iopub.execute_input":"2023-09-18T11:32:15.086735Z","iopub.status.idle":"2023-09-18T11:32:18.088381Z","shell.execute_reply.started":"2023-09-18T11:32:15.086692Z","shell.execute_reply":"2023-09-18T11:32:18.086906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* å‘å¸ƒåˆ° hub ä¸­","metadata":{}},{"cell_type":"code","source":"notebook_login()\n!git config --global credential.helper store","metadata":{"execution":{"iopub.status.busy":"2023-09-18T11:32:21.889698Z","iopub.execute_input":"2023-09-18T11:32:21.890753Z","iopub.status.idle":"2023-09-18T11:32:23.054903Z","shell.execute_reply.started":"2023-09-18T11:32:21.890714Z","shell.execute_reply":"2023-09-18T11:32:23.053514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's fill the `package_to_hub` function:\n- `model`: our trained model.\n- `model_name`: the name of the trained model that we defined in `model_save`\n- `model_architecture`: the model architecture we used, in our case PPO\n- `env_id`: the name of the environment, in our case `LunarLander-v2`\n- `eval_env`: the evaluation environment defined in eval_env\n- `repo_id`: the name of the Hugging Face Hub Repository that will be created/updated `(repo_id = {username}/{repo_name})`\n\nğŸ’¡ **A good name is {username}/{model_architecture}-{env_id}**\n\n- `commit_message`: message of the commit","metadata":{}},{"cell_type":"code","source":"import gymnasium as gym\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom stable_baselines3.common.env_util import make_vec_env\n\nfrom huggingface_sb3 import package_to_hub\n\n# PLACE the variables you've just defined two cells above\n# Define the name of the environment\nenv_id = \"LunarLander-v2\"\n\n# TODO: Define the model architecture we used\nmodel_architecture = \"PPO\"\n\n## Define a repo_id\n## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n## CHANGE WITH YOUR REPO ID\nrepo_id = \"Solitary12138/Load_Moon\" # Change with your repo id, you can't push with mine ğŸ˜„\n\n## Define the commit message\ncommit_message = \"Upload PPO LunarLander-v2 trained agent\"\n\n# Create the evaluation env and set the render_mode=\"rgb_array\"\neval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n\n# PLACE the package_to_hub function you've just filled here\npackage_to_hub(model=model, # Our trained model\n               model_name=model_name, # The name of our trained model\n               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n               env_id=env_id, # Name of the environment\n               eval_env=eval_env, # Evaluation Environment\n               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n               commit_message=commit_message)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T11:35:31.466416Z","iopub.execute_input":"2023-09-18T11:35:31.466950Z","iopub.status.idle":"2023-09-18T11:35:36.049709Z","shell.execute_reply.started":"2023-09-18T11:35:31.466913Z","shell.execute_reply":"2023-09-18T11:35:36.047127Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
