{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chhelp/pytorch-tensors?scriptVersionId=144249794\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Tensors","metadata":{}},{"cell_type":"markdown","source":"* Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the modelâ€™s parameters.","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:06.570031Z","iopub.execute_input":"2023-09-25T10:54:06.571505Z","iopub.status.idle":"2023-09-25T10:54:06.577607Z","shell.execute_reply.started":"2023-09-25T10:54:06.571428Z","shell.execute_reply":"2023-09-25T10:54:06.576251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initializing a Tensor","metadata":{}},{"cell_type":"markdown","source":"* Tensors can be created directly from data. The data type is automatically inferred","metadata":{}},{"cell_type":"code","source":"data = [[1, 2], [3, 4]]\nprint('data type: ', type(data))\nx_data = torch.tensor(data)\nprint('x_data type: ', type(x_data) ,'x_data: ', x_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:06.581883Z","iopub.execute_input":"2023-09-25T10:54:06.582515Z","iopub.status.idle":"2023-09-25T10:54:06.595997Z","shell.execute_reply.started":"2023-09-25T10:54:06.582455Z","shell.execute_reply":"2023-09-25T10:54:06.594634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Tensors can be created from Numpy arrays","metadata":{}},{"cell_type":"code","source":"np_array = np.array(data)\nprint('np_array type: ', type(np_array), 'np_array: ', np_array)\n\nx_np = torch.tensor(np_array)\nprint('x_np type: ', type(x_np), 'x_np: ', x_np)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:06.598204Z","iopub.execute_input":"2023-09-25T10:54:06.598558Z","iopub.status.idle":"2023-09-25T10:54:06.609103Z","shell.execute_reply.started":"2023-09-25T10:54:06.598529Z","shell.execute_reply":"2023-09-25T10:54:06.607737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The new tensor retains the properities (shap, datatype) of the argument tensor, unless explicity overridden","metadata":{}},{"cell_type":"code","source":"x_ones = torch.ones_like(x_data) # retains the properties of x_data\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\n\nx_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\nprint(f\"Random Tensor: \\n {x_rand} \\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:06.610752Z","iopub.execute_input":"2023-09-25T10:54:06.611125Z","iopub.status.idle":"2023-09-25T10:54:06.623406Z","shell.execute_reply.started":"2023-09-25T10:54:06.611094Z","shell.execute_reply":"2023-09-25T10:54:06.622219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* shape is a tuple of tensor dimensions. In the function below, it determines the dimensionality of the output tensor","metadata":{}},{"cell_type":"code","source":"shape = (2, 3,)\nrand_tensor = torch.rand(shape)\none_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"One Tensor: \\n {one_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:06.625163Z","iopub.execute_input":"2023-09-25T10:54:06.625581Z","iopub.status.idle":"2023-09-25T10:54:06.644223Z","shell.execute_reply.started":"2023-09-25T10:54:06.625546Z","shell.execute_reply":"2023-09-25T10:54:06.642872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attributes of a Tensor","metadata":{}},{"cell_type":"markdown","source":"* Tensor attributes describe their shape, datatype, and the device on which they are stored# Attributes of a Tensor","metadata":{}},{"cell_type":"code","source":"tensor = torch.rand(3,4)\n\nprint(tensor)\n\nprint(f\"Shape of tensor: {tensor.shape}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:54:44.177913Z","iopub.execute_input":"2023-09-25T10:54:44.178392Z","iopub.status.idle":"2023-09-25T10:54:44.186915Z","shell.execute_reply.started":"2023-09-25T10:54:44.178354Z","shell.execute_reply":"2023-09-25T10:54:44.185726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Operations on Tensors","metadata":{}},{"cell_type":"markdown","source":"* Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described [here](https://pytorch.org/docs/stable/torch.html)\n* By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!","metadata":{}},{"cell_type":"code","source":"# move our tensor to the GPU if available\nif torch.cuda.is_available():\n    tensor = tensor.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:58:31.328195Z","iopub.execute_input":"2023-09-25T10:58:31.328693Z","iopub.status.idle":"2023-09-25T10:58:31.335187Z","shell.execute_reply.started":"2023-09-25T10:58:31.328637Z","shell.execute_reply":"2023-09-25T10:58:31.333733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Standard numpy-like indexing and sllcing","metadata":{}},{"cell_type":"code","source":"tensor = torch.ones(4, 4)\nprint('First row: ',tensor[0])\nprint('First column: ', tensor[:, 0])\nprint('Last column:', tensor[..., -1])\ntensor[:,1] = 0\nprint(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T10:59:41.550437Z","iopub.execute_input":"2023-09-25T10:59:41.550944Z","iopub.status.idle":"2023-09-25T10:59:41.566048Z","shell.execute_reply.started":"2023-09-25T10:59:41.550899Z","shell.execute_reply":"2023-09-25T10:59:41.564579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Joining tensors you can use `torch.cat` to concatenate a sequence of tensors along a given dimension.","metadata":{}},{"cell_type":"code","source":"t1 = torch.cat([tensor, tensor, tensor], dim=1)\nprint(t1)\n\nt2 = torch.cat([tensor, tensor, tensor], dim=0)\nprint(t2)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:02:49.977461Z","iopub.execute_input":"2023-09-25T11:02:49.977881Z","iopub.status.idle":"2023-09-25T11:02:49.990954Z","shell.execute_reply.started":"2023-09-25T11:02:49.977845Z","shell.execute_reply":"2023-09-25T11:02:49.989659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Arthmetic operations","metadata":{}},{"cell_type":"code","source":"# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\n\ny3 = torch.rand_like(tensor)\ntorch.matmul(tensor, tensor.T, out=y3)\n\n\n# This computes the element-wise product. z1, z2, z3 will have the same value\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\n\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:05:29.950228Z","iopub.execute_input":"2023-09-25T11:05:29.95087Z","iopub.status.idle":"2023-09-25T11:05:29.962874Z","shell.execute_reply.started":"2023-09-25T11:05:29.950836Z","shell.execute_reply":"2023-09-25T11:05:29.961599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Single-element tensors If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`","metadata":{}},{"cell_type":"code","source":"agg = tensor.sum()\nprint(agg, type(agg))\nagg_item = agg.item()\nprint(agg_item, type(agg_item))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:11:38.135749Z","iopub.execute_input":"2023-09-25T11:11:38.136183Z","iopub.status.idle":"2023-09-25T11:11:38.144669Z","shell.execute_reply.started":"2023-09-25T11:11:38.136148Z","shell.execute_reply":"2023-09-25T11:11:38.143464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* In-place operations Operations that store the result into the operand are called in-place. They are denoted by a `_` suffix. For example `x.copy_(y)` `x.t_()` will change `x`\n* In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged","metadata":{}},{"cell_type":"code","source":"print(tensor, \"\\n\")\ntensor.add_(5)\nprint(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:14:43.183735Z","iopub.execute_input":"2023-09-25T11:14:43.184199Z","iopub.status.idle":"2023-09-25T11:14:43.196993Z","shell.execute_reply.started":"2023-09-25T11:14:43.184164Z","shell.execute_reply":"2023-09-25T11:14:43.195735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bridge with NumPy","metadata":{}},{"cell_type":"markdown","source":"* Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other","metadata":{}},{"cell_type":"code","source":"t = torch.ones(5)\nprint(f\"t: {t}\")\n\nn = t.numpy()\nprint(f\"n: {n}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:18:09.856921Z","iopub.execute_input":"2023-09-25T11:18:09.857389Z","iopub.status.idle":"2023-09-25T11:18:09.866182Z","shell.execute_reply.started":"2023-09-25T11:18:09.857354Z","shell.execute_reply":"2023-09-25T11:18:09.864834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* A change in the tensor reflects in the NumPy arrays","metadata":{}},{"cell_type":"code","source":"t.add_(1)\nprint(f\"t: {t}\")\nprint(f\"n: {n}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:19:20.511669Z","iopub.execute_input":"2023-09-25T11:19:20.512195Z","iopub.status.idle":"2023-09-25T11:19:20.521545Z","shell.execute_reply.started":"2023-09-25T11:19:20.512155Z","shell.execute_reply":"2023-09-25T11:19:20.520183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NumPy arrays to Tensor","metadata":{}},{"cell_type":"code","source":"n = np.ones(5)\n\nt = torch.from_numpy(n)\n\nprint(n, type(n))\nprint(t)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:22:06.891747Z","iopub.execute_input":"2023-09-25T11:22:06.892267Z","iopub.status.idle":"2023-09-25T11:22:06.901478Z","shell.execute_reply.started":"2023-09-25T11:22:06.892226Z","shell.execute_reply":"2023-09-25T11:22:06.899967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* change in the NumPy array reflects in the tensor","metadata":{}},{"cell_type":"code","source":"np.add(n, 1, out=n)\nprint(f\"t: {t}\")\nprint(f\"n: {n}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T11:21:32.188559Z","iopub.execute_input":"2023-09-25T11:21:32.189091Z","iopub.status.idle":"2023-09-25T11:21:32.19814Z","shell.execute_reply.started":"2023-09-25T11:21:32.189053Z","shell.execute_reply":"2023-09-25T11:21:32.196868Z"},"trusted":true},"execution_count":null,"outputs":[]}]}