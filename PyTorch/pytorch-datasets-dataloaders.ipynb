{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chhelp/pytorch-datasets-dataloaders?scriptVersionId=144315597\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# DATASETS & DATALOADERS","metadata":{}},{"cell_type":"markdown","source":"* PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-load datasets as well as your own data\n* `Dataset` stores the samples and their corresponding label, and `DataLoader` wraps an iteralble around the `Dataset` to enable easy access to the sample","metadata":{}},{"cell_type":"markdown","source":"## Loading a Dataset","metadata":{}},{"cell_type":"markdown","source":"* `root` is the path where the train/test data is stored\n* `train` specifies training or test dataset\n* `download=True` downloads the data from the internet if it's not availbale at `root`\n* `transform` and `target_transform` specify the feature adnd label transformations","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\nprint(\"torch version\", torch.__version__)\n\ntraining_data = datasets.FashionMNIST(\n    root = 'data',\n    train = True,\n    download = True,\n    transform = ToTensor()\n)\n\n\ntest_data = datasets.FashionMNIST(\n    root = 'data',\n    train = False,\n    download = True,\n    transform = ToTensor()\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:19.55635Z","iopub.execute_input":"2023-09-26T11:00:19.556757Z","iopub.status.idle":"2023-09-26T11:00:25.014278Z","shell.execute_reply.started":"2023-09-26T11:00:19.556726Z","shell.execute_reply":"2023-09-26T11:00:25.012998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Iterating and Visualizing the Dataset","metadata":{}},{"cell_type":"markdown","source":"* We can index `Datasets` manually like a list: `training_data[index]`\n* We use `matplotlib` to visualize some samples in our training data","metadata":{}},{"cell_type":"code","source":"labels_map = {\n    0: \"T-Shirt\",\n    1: \"Trouser\",\n    2: \"Pullover\",\n    3: \"Dress\",\n    4: \"Coat\",\n    5: \"Sandal\",\n    6: \"Shirt\",\n    7: \"Sneaker\",\n    8: \"Bag\",\n    9: \"Ankle Boot\",\n}\n\n\nfigure = plt.figure(figsize=(8, 8))\n\ncols, rows = 3, 3\n\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n    img, label = training_data[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(labels_map[label])\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:08:00.14545Z","iopub.execute_input":"2023-09-26T11:08:00.145839Z","iopub.status.idle":"2023-09-26T11:08:00.912434Z","shell.execute_reply.started":"2023-09-26T11:08:00.14581Z","shell.execute_reply":"2023-09-26T11:08:00.911277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a Custom Dataset for your files","metadata":{}},{"cell_type":"markdown","source":"* A custom Dataset class must implement three function `__init__`, `__len__`, `__getitem`\n* Take a look at this implementation, the FashionMNIST images are stroed in a directory `img_dir`, and their labels are stored separately in a CSV file `annotations_file`","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torchvision.io import read_image\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_tarnsform = target_transform\n        \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_tarnsform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:20:19.61338Z","iopub.execute_input":"2023-09-26T11:20:19.613808Z","iopub.status.idle":"2023-09-26T11:20:19.916901Z","shell.execute_reply.started":"2023-09-26T11:20:19.613774Z","shell.execute_reply":"2023-09-26T11:20:19.915714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \\_\\_init\\_\\_","metadata":{}},{"cell_type":"markdown","source":"* The `__init__` function is run once when instantiating the Dataset object.\n* We initialize the directory containing the images, the annotations file, and both transforms","metadata":{}},{"cell_type":"markdown","source":"* The labels.csv file looks like\n```example\ntshirt1.jpg, 0\ntshirt2.jpg, 0\n......\nankleboot999.jpg, 9\n```","metadata":{}},{"cell_type":"code","source":"def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n    self.img_labels = pd.read_csv(annotations_file)\n    self.img_dir = img_dir\n    self.transform = transform\n    self.target_transform = target_transform","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:25:00.580705Z","iopub.execute_input":"2023-09-26T11:25:00.581504Z","iopub.status.idle":"2023-09-26T11:25:00.588668Z","shell.execute_reply.started":"2023-09-26T11:25:00.581465Z","shell.execute_reply":"2023-09-26T11:25:00.58728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \\_\\_len\\_\\_","metadata":{}},{"cell_type":"markdown","source":"* The `__len__` function returns the number of samples in our dataset","metadata":{}},{"cell_type":"code","source":"def __len__(self):\n    return len(self.img_labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \\_\\_getitem\\_\\_","metadata":{}},{"cell_type":"markdown","source":"* The `__getitem__` function loads an returns a sample from the dataset at the given index `idx`\n* Based on the index, it identifies the image's location on disk, converts that to a tensor using `read_image`, retrieves the corresponding label from the csv data in `self.img_labels`, call the transform functions on them(if applicable), and returns the tensor image and corresponding label in a tuple","metadata":{}},{"cell_type":"code","source":"def __getitem__(self, idx):\n    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n    image = read_image(img_path)\n    label = self.img_labels.iloc[idx, 1]\n    if self.transform:\n        image = self.transform(image)\n    if self.target_transform:\n        label = self.target_transform(label)\n    return image, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing your data for training with DataLoaders","metadata":{}},{"cell_type":"markdown","source":"* The `Dataset` retrieves our dataset's features and labels one sample at a time\n* While training a model, we typically want to pass samples in **minibatches**, reshuffle the data at every epoch to reduce model overfitting, and use Python's `multiprocessing` to speed up data retriveval\n* `DataLoader` is an iterable that abstracts this complexity for us in an easy API","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:47:27.717344Z","iopub.execute_input":"2023-09-26T11:47:27.71813Z","iopub.status.idle":"2023-09-26T11:47:27.724399Z","shell.execute_reply.started":"2023-09-26T11:47:27.718092Z","shell.execute_reply":"2023-09-26T11:47:27.72303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Iterate through the DataLoader","metadata":{}},{"cell_type":"markdown","source":"* We have loaded that dataset into the `DataLoader` and can iterate through the dataset as needed\n* Each iteration below returns a batch of `train_features` and `train_labels`(containing `batch_size=64` features and labels respectively)\n* Because we specified `shuffle=True`, affer we iterate over all batches the data is shuffled(for finer-grained control over the data loading order, take a look at Samplers)","metadata":{}},{"cell_type":"code","source":"# Display image and label.\ntrain_features, train_labels = next(iter(train_dataloader))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_features[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img, cmap=\"gray\")\nplt.show()\nprint(f\"Label: {label}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:47:30.309384Z","iopub.execute_input":"2023-09-26T11:47:30.309767Z","iopub.status.idle":"2023-09-26T11:47:30.569696Z","shell.execute_reply.started":"2023-09-26T11:47:30.30974Z","shell.execute_reply":"2023-09-26T11:47:30.568645Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
